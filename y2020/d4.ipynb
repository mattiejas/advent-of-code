{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('advent-of-code': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "3451c0811e19b5d04077f1fa8065ac00cb5d6199fe8db8edb664c484c0569830"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "source": [
    "# Day 4: Passport Processing\n",
    "You arrive at the airport only to realize that you grabbed your North Pole Credentials instead of your passport. While these documents are extremely similar, North Pole Credentials aren't issued by a country and therefore aren't actually valid documentation for travel in most of the world.\n",
    "\n",
    "It seems like you're not the only one having problems, though; a very long line has formed for the automatic passport scanners, and the delay could upset your travel itinerary.\n",
    "\n",
    "Due to some questionable network security, you realize you might be able to solve both of these problems at the same time.\n",
    "\n",
    "The automatic passport scanners are slow because they're having trouble detecting which passports have all required fields. The expected fields are as follows:\n",
    "\n",
    "```\n",
    "byr (Birth Year)\n",
    "iyr (Issue Year)\n",
    "eyr (Expiration Year)\n",
    "hgt (Height)\n",
    "hcl (Hair Color)\n",
    "ecl (Eye Color)\n",
    "pid (Passport ID)\n",
    "cid (Country ID)\n",
    "```\n",
    "\n",
    "Passport data is validated in batch files (your puzzle input). Each passport is represented as a sequence of key:value pairs separated by spaces or newlines. Passports are separated by blank lines.\n",
    "\n",
    "Here is an example batch file containing four passports:\n",
    "\n",
    "```\n",
    "ecl:gry pid:860033327 eyr:2020 hcl:#fffffd\n",
    "byr:1937 iyr:2017 cid:147 hgt:183cm\n",
    "\n",
    "iyr:2013 ecl:amb cid:350 eyr:2023 pid:028048884\n",
    "hcl:#cfa07d byr:1929\n",
    "\n",
    "hcl:#ae17e1 iyr:2013\n",
    "eyr:2024\n",
    "ecl:brn pid:760753108 byr:1931\n",
    "hgt:179cm\n",
    "\n",
    "hcl:#cfa07d eyr:2025 pid:166559648\n",
    "iyr:2011 ecl:brn hgt:59in\n",
    "```\n",
    "\n",
    "The first passport is valid - all eight fields are present. The second passport is invalid - it is missing hgt (the Height field).\n",
    "\n",
    "The third passport is interesting; the only missing field is cid, so it looks like data from North Pole Credentials, not a passport at all! Surely, nobody would mind if you made the system temporarily ignore missing cid fields. Treat this \"passport\" as valid.\n",
    "\n",
    "The fourth passport is missing two fields, cid and byr. Missing cid is fine, but missing any other field is not, so this passport is invalid.\n",
    "\n",
    "According to the above rules, your improved system would report 2 valid passports.\n",
    "\n",
    "Count the number of valid passports - those that have all required fields. Treat cid as optional. In your batch file, how many passports are valid?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([1, 0, 0, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "def hot_encode(keys):\n",
    "    # ['byr', 'cid', 'ecl', 'eyr', 'hcl', 'hgt', 'iyr', 'pid']\n",
    "    he = np.array([0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    if 'byr' in keys:\n",
    "        he += [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    if 'cid' in keys:\n",
    "        he += [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "    if 'ecl' in keys:\n",
    "        he += [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "    if 'eyr' in keys:\n",
    "        he += [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "    if 'hcl' in keys:\n",
    "        he += [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "    if 'hgt' in keys:\n",
    "        he += [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "    if 'iyr' in keys:\n",
    "        he += [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "    if 'pid' in keys:\n",
    "        he += [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    return he\n",
    "\n",
    "def read_credentials_from_file(filname):\n",
    "    creds = []\n",
    "    with open(filname, 'r') as f:\n",
    "        cred = {}\n",
    "        for line in f:\n",
    "            if line == '\\n':\n",
    "                creds.append(hot_encode(dict(sorted(cred.items())).keys()))\n",
    "                cred = {}\n",
    "                continue\n",
    "            \n",
    "            kv = [vals.split(':') for vals in line.strip().split(' ')]\n",
    "            for key, value in kv:\n",
    "                cred[key] = value\n",
    "    return creds\n",
    "    \n",
    "creds = read_credentials_from_file('input/d4.dat')\n",
    "print(creds[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "\n",
    "X_train = np.array(list(itertools.product([0, 1], repeat=8)))\n",
    "y_train = np.array([False] * X_train.shape[0])\n",
    "\n",
    "idx_1 = np.all(X_train == [1, 1, 1, 1, 1, 1, 1, 1], axis=1)\n",
    "y_train[idx_1] = True\n",
    "idx_2 = np.all(X_train == [1, 0, 1, 1, 1, 1, 1, 1], axis=1)\n",
    "y_train[idx_2] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, n_estimators=1)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1, bootstrap=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "prediction = clf.predict(creds)\n",
    "prediction.sum()"
   ]
  }
 ]
}